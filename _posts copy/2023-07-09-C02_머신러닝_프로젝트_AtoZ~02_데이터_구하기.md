---
layout: single
title: "[C02 머신러닝 프로젝트 AtoZ]02 데이터 구하기"
categories: ml
tag: [python, ml]
toc: true
author_profile: false
typora-root-url: ../
sidebar:
  nav: "counts"
---

 
<nav class="cods"><h2>C02 머신러닝 프로젝트 AtoZ 시리즈 목차</h2><ol><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~01_목표설계/">01 목표설계</a></li><li><p>(현재 글) 02 데이터 구하기</p></li><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~03_데이터_구조_확인/">03 데이터 구조 확인</a></li><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~04_테스트_세트_만드는_방법_개선/">04 테스트 세트 만드는 방법 개선</a></li><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~05_테스트_세트_샘플링/">05 테스트 세트 샘플링</a></li><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~06_데이터_시각화/">06 데이터 시각화</a></li><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~07_데이터_전처리/">07 데이터 전처리</a></li><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~08_sklearn_설계원칙/">08 sklearn 설계원칙</a></li><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~09_파이프라인_만들기/">09 파이프라인 만들기</a></li><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~10_모델_선택과_훈련/">10 모델 선택과 훈련</a></li><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~11_모델_세부_튜닝/">11 모델 세부 튜닝</a></li></ol></nav>

## 1. 데이터를 다운로드하는 함수 작성
- 실제 프로젝트에서는 ipynb 파일 안에 def로 함수를 만드는 것이 아니라, py 파일로 만들어서 사용한다.
- 해당 함수명으로 파일을 만들고 import 해서 사용하면 된다.
 

``` python
import os
import tarfile
import urllib

DOWNLOAD_ROOT = "https://raw.githubusercontent.com/ageron/handson-ml2/master/"
# 우리가 다룰 path도 여기서는 하나이지만, 복잡한 경로를 다룬다면 아래처럼 os 모듈을 사용하면 좋다.
HOUSING_PATH = os.path.join("datasets", "housing")
HOUSING_URL = DOWNLOAD_ROOT + "datasets/housing/housing.tgz"

def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):
    # os.makedirs()는 이미 존재하는 디렉토리를 만들려고 하면 에러가 발생하므로, exist_ok=True로 설정해준다.
    os.makedirs(housing_path, exist_ok=True)
    tgz_path = os.path.join(housing_path, "housing.tgz")
    # urllib urlretrieve() 함수는 url로 지정한 파일을 로컬에 다운로드 한다.
    urllib.request.urlretrieve(housing_url, tgz_path)
    # tarfile.open() 함수는 압축파일을 열어준다.
    housing_tgz = tarfile.open(tgz_path)
    # extractall() 함수는 압축파일을 풀어준다.
    housing_tgz.extractall(path=housing_path)
    housing_tgz.close()
```
- 사실 이 데이터는 바뀌지도 않고, 다운로드할 것이 하나라 그냥 들어가서 다운받아 압축을 풀면 된다.
- 하지만 하나의 루트 사이트에서 정기적으로 바뀌는 여러가지 URL의 데이터들을 다운로드 한다면 위처럼 함수를 만드는 편이 훨씬 좋다.
 
## 2. 데이터를 데이터프레임으로 읽어오는 함수 작성
 

``` python
import pandas as pd

def load_housing_data(housing_path=HOUSING_PATH):
    csv_path = os.path.join(housing_path, "housing.csv")
    return pd.read_csv(csv_path)
```
## 3. 1과 2에서 정의한 두 함수를 실행해 데이터를 fetch, load
 

``` python
fetch_housing_data()
housing = load_housing_data()

housing.head()
```
load_housing_data() 함수는 따로 functions 폴더를 만들어 저장했다고 가정하고 다음 장을 진행한다.
 
