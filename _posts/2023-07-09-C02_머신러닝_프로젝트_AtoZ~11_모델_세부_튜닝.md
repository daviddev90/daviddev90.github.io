---
layout: single
title: "[C02 머신러닝 프로젝트 AtoZ]11 모델 세부 튜닝"
categories: ml
tag: [python, ml]
toc: true
author_profile: false
typora-root-url: ../
sidebar:
  nav: "counts"
---

 
<nav class="cods"><h2>C02 머신러닝 프로젝트 AtoZ posts</h2><ol><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~01_목표설계/">01 목표설계</a></li><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~02_데이터_구하기/">02 데이터 구하기</a></li><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~03_데이터_구조_확인/">03 데이터 구조 확인</a></li><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~04_테스트_세트_만드는_방법_개선/">04 테스트 세트 만드는 방법 개선</a></li><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~05_테스트_세트_샘플링/">05 테스트 세트 샘플링</a></li><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~06_데이터_시각화/">06 데이터 시각화</a></li><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~07_데이터_전처리/">07 데이터 전처리</a></li><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~08_sklearn_설계원칙/">08 sklearn 설계원칙</a></li><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~09_파이프라인_만들기/">09 파이프라인 만들기</a></li><li><a href="/ml/C02_머신러닝_프로젝트_AtoZ~10_모델_선택과_훈련/">10 모델 선택과 훈련</a></li><li><p>(current) 11 모델 세부 튜닝</p></li></ol></nav>

### 그리드 탐색(GridSearchCV)
- 탐색하려는 하이퍼파라미터와 시도해볼 값 지정
- 가능한 모든 하이퍼파라미터 조합에 대해 교차 검증을 사용해 평가
 

``` python
# 데이터 불러오기
import pandas as pd
import numpy as np
housing_prepared = pd.read_csv("housing_prepared.csv", index_col=0).reset_index(drop=True)
housing_labels = pd.read_csv("housing_labels.csv", index_col=0).reset_index(drop=True)
housing_labels = housing_labels.values.ravel()
housing = pd.read_csv("housing.csv", index_col=0).reset_index(drop=True)
```

``` python
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor

param_grid = [
  {
    'n_estimators': [3, 10, 30],
    'max_features': [2, 4, 6, 8]
  },
  {
    'bootstrap': [False],
    'n_estimators': [3, 10],
    'max_features': [2, 3, 4]
  }
]

forest_reg = RandomForestRegressor()

grid_search = GridSearchCV(
  forest_reg, param_grid, cv=5,
  scoring='neg_mean_squared_error',
  return_train_score=True
)

grid_search.fit(housing_prepared, housing_labels)

```

<div class="op_wrap"><op>GridSearchCV(cv=5, estimator=RandomForestRegressor(),
</op><op>             param_grid=[{'max_features': [2, 4, 6, 8],
</op><op>                          'n_estimators': [3, 10, 30]},
</op><op>                         {'bootstrap': [False], 'max_features': [2, 3, 4],
</op><op>                          'n_estimators': [3, 10]}],
</op><op>             return_train_score=True, scoring='neg_mean_squared_error')</op></div>

#### 해석
- 첫번째 dict에 있는 조합을 시도함
- 이어서 두 번째 dict에 있는 조합을 시도하되, bootstrap 하이퍼파라미터를 False로
- 총 12 + 6 = 18개 조합을 탐색하고, 각각 5번 모델을 훈련시킴(5-fold)
 

``` python
# 최적의 조합
grid_search.best_params_
```

<div class="op_wrap"><op>{'max_features': 6, 'n_estimators': 30}</op></div>


``` python
# 최적의 추정기
grid_search.best_estimator_
```

<div class="op_wrap"><op>RandomForestRegressor(max_features=6, n_estimators=30)</op></div>


``` python
# 평가 점수 확인
grid_search.cv_results_
```
## 랜덤 탐색
- 적은 수의 조합을 탐색할 때는 모든 조합을 다 시도해보는 GridSearch가 괜찮음
- 하지만 탐색할 것이 많아진다면 RandomizedSearchCv를 사용하는 것이 좋음
 

``` python
# 특성 중요도 확인
feature_importances = grid_search.best_estimator_.feature_importances_
feature_importances
```

<div class="op_wrap"><op>array([8.64292565e-02, 8.50441983e-02, 4.05437328e-02, 2.52969951e-02,
</op><op>       1.86938557e-02, 2.35435412e-02, 2.05627506e-02, 4.08425076e-01,
</op><op>       2.34638915e-02, 9.36833412e-02, 2.16456345e-02, 1.45090174e-02,
</op><op>       1.28755720e-01, 2.06302580e-05, 4.11047008e-03, 5.27188872e-03])</op></div>


``` python
from functions.full_pipeline import FullPipeline
full_pipeline = FullPipeline()
housing_prepared = full_pipeline.fit_transform(housing)

num_attribs = ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']

# 특성 중요도 옆에 이름 표시
extra_attribs = ["rooms_per_hhold", "pop_per_hhold", "bedrooms_per_room"]
cat_encoder = full_pipeline.full_pipeline.named_transformers_["cat"]
cat_one_hot_attribs = list(cat_encoder.categories_[0])
attributes = num_attribs + extra_attribs + cat_one_hot_attribs
sorted(zip(feature_importances, attributes), reverse=True)

```

<div class="op_wrap"><op>[(0.40842507569601877, 'median_income'),
</op><op> (0.12875572035073693, 'INLAND'),
</op><op> (0.09368334124118224, 'pop_per_hhold'),
</op><op> (0.08642925653641972, 'longitude'),
</op><op> (0.08504419827611975, 'latitude'),
</op><op> (0.0405437327993139, 'housing_median_age'),
</op><op> (0.025296995125728642, 'total_rooms'),
</op><op> (0.023543541249955495, 'population'),
</op><op> (0.023463891452147563, 'rooms_per_hhold'),
</op><op> (0.021645634457764098, 'bedrooms_per_room'),
</op><op> (0.020562750611053754, 'households'),
</op><op> (0.01869385572404301, 'total_bedrooms'),
</op><op> (0.014509017419666452, '<1H OCEAN'),
</op><op> (0.005271888719606761, 'NEAR OCEAN'),
</op><op> (0.004110470082200306, 'NEAR BAY'),
</op><op> (2.063025804264065e-05, 'ISLAND')]</op></div>

## 시스템 평가
- 테스트 세트에서 예측 변수와 레이블을 분리하고
- full_pipeline의 transform()을 호출해 데이터 변환 (테스트 세트를 훈련하면 안 되므로 fit 호출금지)
- 테스트 세트에서 최종 모델 평가
 

``` python

from sklearn.metrics import mean_squared_error
strat_test_set = pd.read_csv("../datasets/temp/strat_test_set.csv", index_col=0).reset_index(drop=True)

final_model = grid_search.best_estimator_

X_test = strat_test_set.drop("median_house_value", axis=1)
y_test = strat_test_set["median_house_value"].copy()

X_test_prepared = full_pipeline.transform(X_test)

final_predictions = final_model.predict(X_test_prepared)


final_mse = mean_squared_error(y_test, final_predictions)
final_rmse = np.sqrt(final_mse)
final_rmse
```

<div class="op_wrap"><op>  warnings.warn(
</op><br></div>

<div class="op_wrap"><op>62756.60972413835</op></div>

